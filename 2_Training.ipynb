{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optical-theorem",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "This notebook loads a PDF dataset and trains an XGBoost model to classify the structure of a metallic nanoparticle based on its PDF. The model is trained to predict a specific atomic model for an atomic pair distribution (PDF) from a total scattering experiment on a metallic nanoparticle. There are 4044 atomic models to predict, as seen in the xyz_files folder containing all of them. The model is given PDFs with 300 datapoints from r = 0 Å to r = 30 Å, with a step length of 0.1. \n",
    "\n",
    "The model is trained for 500 epochs with early stopping after 5 rounds of no improvement in validation loss. The learning rate is 0.15 and the max depth is 3. There is no hyperparameter optimization.\n",
    "\n",
    "**How to use:** Run the cells underneath from top to bottom \n",
    "\n",
    "The first cell imports packages and functions from the backend. The second cell imports a PDF dataset. The third cell trains an XGBoost model. The fourth cell saves the trained XGBoost model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-ontario",
   "metadata": {},
   "source": [
    "# Import packages and functions from backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "auburn-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, os.path, h5py, time\n",
    "\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "sys.path.append(\"Backend\")\n",
    "\n",
    "from training import load_PDFs, ML, sort_filenames, get_training_data_backend\n",
    "sorted_filenames_flat, xyz_path = get_training_data_backend(xyz_folder_name = \"natoms200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-party",
   "metadata": {},
   "source": [
    "# Import PDF dataset\n",
    "\n",
    "Load PDF dataset from the folder \"/PDF_datasets/\". Specify the folder name of the dataset you want to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rapid-folder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>qmin</th>\n",
       "      <th>qmax</th>\n",
       "      <th>qdamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003952</td>\n",
       "      <td>0.021042</td>\n",
       "      <td>0.024643</td>\n",
       "      <td>0.024216</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>0.029007</td>\n",
       "      <td>0.036682</td>\n",
       "      <td>0.032959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000710</td>\n",
       "      <td>-0.001879</td>\n",
       "      <td>-0.002951</td>\n",
       "      <td>-0.004070</td>\n",
       "      <td>-0.004940</td>\n",
       "      <td>-0.005562</td>\n",
       "      <td>-0.006134</td>\n",
       "      <td>1.890625</td>\n",
       "      <td>19.703125</td>\n",
       "      <td>0.025574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045227</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>-0.058136</td>\n",
       "      <td>-0.057953</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.020294</td>\n",
       "      <td>-0.050507</td>\n",
       "      <td>-0.100464</td>\n",
       "      <td>-0.058289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>-0.006065</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.011139</td>\n",
       "      <td>-0.002506</td>\n",
       "      <td>1.344727</td>\n",
       "      <td>13.640625</td>\n",
       "      <td>0.019730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009575</td>\n",
       "      <td>-0.025497</td>\n",
       "      <td>-0.034088</td>\n",
       "      <td>-0.044067</td>\n",
       "      <td>-0.060272</td>\n",
       "      <td>-0.068237</td>\n",
       "      <td>-0.078186</td>\n",
       "      <td>-0.094238</td>\n",
       "      <td>-0.101562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.890137</td>\n",
       "      <td>20.843750</td>\n",
       "      <td>0.018417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003716</td>\n",
       "      <td>-0.012566</td>\n",
       "      <td>-0.026947</td>\n",
       "      <td>-0.038391</td>\n",
       "      <td>-0.040405</td>\n",
       "      <td>-0.041595</td>\n",
       "      <td>-0.055115</td>\n",
       "      <td>-0.076111</td>\n",
       "      <td>-0.085327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>-0.004181</td>\n",
       "      <td>-0.009781</td>\n",
       "      <td>-0.006809</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>-0.001470</td>\n",
       "      <td>-0.007866</td>\n",
       "      <td>1.306641</td>\n",
       "      <td>14.140625</td>\n",
       "      <td>0.022705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>-0.008621</td>\n",
       "      <td>-0.029907</td>\n",
       "      <td>-0.032837</td>\n",
       "      <td>-0.021988</td>\n",
       "      <td>-0.027771</td>\n",
       "      <td>-0.055054</td>\n",
       "      <td>-0.071289</td>\n",
       "      <td>-0.060638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.008049</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>1.341797</td>\n",
       "      <td>13.468750</td>\n",
       "      <td>0.017685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56140</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.022720</td>\n",
       "      <td>-0.023865</td>\n",
       "      <td>-0.014214</td>\n",
       "      <td>-0.022751</td>\n",
       "      <td>-0.050629</td>\n",
       "      <td>-0.066956</td>\n",
       "      <td>-0.058563</td>\n",
       "      <td>-0.052338</td>\n",
       "      <td>-0.071899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>-0.001161</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>0.639648</td>\n",
       "      <td>13.531250</td>\n",
       "      <td>0.029572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56141</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>-0.004852</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>-0.007774</td>\n",
       "      <td>-0.002640</td>\n",
       "      <td>-0.003136</td>\n",
       "      <td>-0.014076</td>\n",
       "      <td>-0.010162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>1.585938</td>\n",
       "      <td>21.593750</td>\n",
       "      <td>0.011719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56142</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>-0.010963</td>\n",
       "      <td>-0.021896</td>\n",
       "      <td>-0.015640</td>\n",
       "      <td>-0.015572</td>\n",
       "      <td>-0.033325</td>\n",
       "      <td>-0.040894</td>\n",
       "      <td>-0.029816</td>\n",
       "      <td>-0.035187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.682617</td>\n",
       "      <td>17.078125</td>\n",
       "      <td>0.036774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56143</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061584</td>\n",
       "      <td>0.034698</td>\n",
       "      <td>-0.058594</td>\n",
       "      <td>-0.097839</td>\n",
       "      <td>-0.034454</td>\n",
       "      <td>0.034576</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>-0.086609</td>\n",
       "      <td>-0.133179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001886</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-0.003876</td>\n",
       "      <td>-0.007084</td>\n",
       "      <td>-0.002823</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>12.265625</td>\n",
       "      <td>0.039276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56144</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.008278</td>\n",
       "      <td>-0.004063</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>-0.011490</td>\n",
       "      <td>-0.019623</td>\n",
       "      <td>-0.014465</td>\n",
       "      <td>-0.013412</td>\n",
       "      <td>-0.027664</td>\n",
       "      <td>-0.037323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000856</td>\n",
       "      <td>-0.004227</td>\n",
       "      <td>-0.004467</td>\n",
       "      <td>-0.001804</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.005249</td>\n",
       "      <td>-0.005470</td>\n",
       "      <td>1.438477</td>\n",
       "      <td>15.484375</td>\n",
       "      <td>0.019882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56145 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1         2         3         4         5         6         7  \\\n",
       "0      0.0  0.003952  0.021042  0.024643  0.024216  0.038086  0.038422   \n",
       "1      0.0  0.045227  0.011414 -0.058136 -0.057953  0.006577  0.020294   \n",
       "2      0.0 -0.009575 -0.025497 -0.034088 -0.044067 -0.060272 -0.068237   \n",
       "3      0.0 -0.003716 -0.012566 -0.026947 -0.038391 -0.040405 -0.041595   \n",
       "4      0.0  0.005413 -0.008621 -0.029907 -0.032837 -0.021988 -0.027771   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "56140  0.0 -0.022720 -0.023865 -0.014214 -0.022751 -0.050629 -0.066956   \n",
       "56141  0.0  0.003487 -0.004852  0.000344  0.001952 -0.007774 -0.002640   \n",
       "56142  0.0  0.002918 -0.010963 -0.021896 -0.015640 -0.015572 -0.033325   \n",
       "56143  0.0  0.061584  0.034698 -0.058594 -0.097839 -0.034454  0.034576   \n",
       "56144  0.0 -0.008278 -0.004063 -0.001212 -0.011490 -0.019623 -0.014465   \n",
       "\n",
       "              8         9        10  ...       294       295       296  \\\n",
       "0      0.029007  0.036682  0.032959  ... -0.000710 -0.001879 -0.002951   \n",
       "1     -0.050507 -0.100464 -0.058289  ...  0.013191  0.001565 -0.006065   \n",
       "2     -0.078186 -0.094238 -0.101562  ...  0.000738  0.001171  0.000800   \n",
       "3     -0.055115 -0.076111 -0.085327  ...  0.000949 -0.004181 -0.009781   \n",
       "4     -0.055054 -0.071289 -0.060638  ...  0.003008  0.000843  0.003641   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "56140 -0.058563 -0.052338 -0.071899  ... -0.000478 -0.000728 -0.001161   \n",
       "56141 -0.003136 -0.014076 -0.010162  ...  0.004654  0.004879  0.004929   \n",
       "56142 -0.040894 -0.029816 -0.035187  ...  0.000141  0.000181  0.000470   \n",
       "56143  0.008232 -0.086609 -0.133179  ... -0.001886  0.003902  0.002802   \n",
       "56144 -0.013412 -0.027664 -0.037323  ... -0.000856 -0.004227 -0.004467   \n",
       "\n",
       "            297       298       299       300      qmin       qmax     qdamp  \n",
       "0     -0.004070 -0.004940 -0.005562 -0.006134  1.890625  19.703125  0.025574  \n",
       "1      0.002460  0.014534  0.011139 -0.002506  1.344727  13.640625  0.019730  \n",
       "2      0.001485  0.001865  0.001393  0.002077  0.890137  20.843750  0.018417  \n",
       "3     -0.006809 -0.000596 -0.001470 -0.007866  1.306641  14.140625  0.022705  \n",
       "4      0.007980  0.008049  0.004154  0.002710  1.341797  13.468750  0.017685  \n",
       "...         ...       ...       ...       ...       ...        ...       ...  \n",
       "56140 -0.001184 -0.000822 -0.000724 -0.001116  0.639648  13.531250  0.029572  \n",
       "56141  0.004967  0.004807  0.004498  0.004189  1.585938  21.593750  0.011719  \n",
       "56142  0.000423  0.000205  0.000345  0.000562  0.682617  17.078125  0.036774  \n",
       "56143 -0.003876 -0.007084 -0.002823  0.003088  0.539062  12.265625  0.039276  \n",
       "56144 -0.001804 -0.002028 -0.005249 -0.005470  1.438477  15.484375  0.019882  \n",
       "\n",
       "[56145 rows x 303 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder_name = \"big_seed37\"\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_PDFs(folder_name)\n",
    "display(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-authority",
   "metadata": {},
   "source": [
    "# Train XGBoost model\n",
    "\n",
    "Train the XGBoost model on the loaded PDF dataset. n_threads specifies how many CPU cores are used by XGBoost. Early stopping is turned on with 5 early stopping rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e36adeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 37\n"
     ]
    }
   ],
   "source": [
    "import torch, random\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "seed = 37\n",
    "torch.manual_seed(seed)\n",
    "pl.seed_everything(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-mexican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent on making data ready: 0.011579283078511556  min\n",
      "Training model\n",
      "[0]\ttrain-mlogloss:3.93934\tval-mlogloss:4.16416\n",
      "[1]\ttrain-mlogloss:2.97387\tval-mlogloss:3.31754\n",
      "[2]\ttrain-mlogloss:2.59671\tval-mlogloss:2.99102\n",
      "[3]\ttrain-mlogloss:2.32722\tval-mlogloss:2.75574\n",
      "[4]\ttrain-mlogloss:2.11365\tval-mlogloss:2.56968\n",
      "[5]\ttrain-mlogloss:1.93692\tval-mlogloss:2.41452\n",
      "[6]\ttrain-mlogloss:1.78656\tval-mlogloss:2.28227\n",
      "[7]\ttrain-mlogloss:1.65610\tval-mlogloss:2.16725\n",
      "[8]\ttrain-mlogloss:1.54141\tval-mlogloss:2.06568\n",
      "[9]\ttrain-mlogloss:1.43994\tval-mlogloss:1.97557\n",
      "[10]\ttrain-mlogloss:1.34934\tval-mlogloss:1.89479\n",
      "[11]\ttrain-mlogloss:1.26712\tval-mlogloss:1.82139\n",
      "[12]\ttrain-mlogloss:1.19233\tval-mlogloss:1.75454\n",
      "[13]\ttrain-mlogloss:1.12457\tval-mlogloss:1.69385\n",
      "[14]\ttrain-mlogloss:1.06231\tval-mlogloss:1.63754\n",
      "[15]\ttrain-mlogloss:1.00514\tval-mlogloss:1.58552\n",
      "[16]\ttrain-mlogloss:0.95227\tval-mlogloss:1.53717\n",
      "[17]\ttrain-mlogloss:0.90353\tval-mlogloss:1.49308\n",
      "[18]\ttrain-mlogloss:0.85793\tval-mlogloss:1.45161\n",
      "[19]\ttrain-mlogloss:0.81564\tval-mlogloss:1.41297\n",
      "[20]\ttrain-mlogloss:0.77630\tval-mlogloss:1.37683\n",
      "[21]\ttrain-mlogloss:0.73940\tval-mlogloss:1.34297\n",
      "[22]\ttrain-mlogloss:0.70479\tval-mlogloss:1.31132\n",
      "[23]\ttrain-mlogloss:0.67230\tval-mlogloss:1.28122\n",
      "[24]\ttrain-mlogloss:0.64182\tval-mlogloss:1.25302\n",
      "[25]\ttrain-mlogloss:0.61309\tval-mlogloss:1.22679\n",
      "[26]\ttrain-mlogloss:0.58593\tval-mlogloss:1.20143\n",
      "[27]\ttrain-mlogloss:0.56015\tval-mlogloss:1.17753\n",
      "[28]\ttrain-mlogloss:0.53582\tval-mlogloss:1.15489\n",
      "[29]\ttrain-mlogloss:0.51285\tval-mlogloss:1.13357\n",
      "[30]\ttrain-mlogloss:0.49118\tval-mlogloss:1.11325\n",
      "[31]\ttrain-mlogloss:0.47046\tval-mlogloss:1.09405\n",
      "[32]\ttrain-mlogloss:0.45080\tval-mlogloss:1.07535\n",
      "[33]\ttrain-mlogloss:0.43202\tval-mlogloss:1.05770\n",
      "[34]\ttrain-mlogloss:0.41432\tval-mlogloss:1.04088\n",
      "[35]\ttrain-mlogloss:0.39746\tval-mlogloss:1.02466\n",
      "[36]\ttrain-mlogloss:0.38127\tval-mlogloss:1.00946\n",
      "[37]\ttrain-mlogloss:0.36590\tval-mlogloss:0.99478\n",
      "[38]\ttrain-mlogloss:0.35117\tval-mlogloss:0.98080\n",
      "[39]\ttrain-mlogloss:0.33720\tval-mlogloss:0.96732\n",
      "[40]\ttrain-mlogloss:0.32379\tval-mlogloss:0.95452\n",
      "[41]\ttrain-mlogloss:0.31093\tval-mlogloss:0.94187\n",
      "[42]\ttrain-mlogloss:0.29875\tval-mlogloss:0.92993\n",
      "[43]\ttrain-mlogloss:0.28708\tval-mlogloss:0.91846\n",
      "[44]\ttrain-mlogloss:0.27588\tval-mlogloss:0.90742\n",
      "[45]\ttrain-mlogloss:0.26520\tval-mlogloss:0.89679\n",
      "[46]\ttrain-mlogloss:0.25498\tval-mlogloss:0.88634\n",
      "[47]\ttrain-mlogloss:0.24516\tval-mlogloss:0.87640\n",
      "[48]\ttrain-mlogloss:0.23585\tval-mlogloss:0.86697\n",
      "[49]\ttrain-mlogloss:0.22689\tval-mlogloss:0.85789\n",
      "[50]\ttrain-mlogloss:0.21831\tval-mlogloss:0.84884\n",
      "[51]\ttrain-mlogloss:0.21008\tval-mlogloss:0.84015\n",
      "[52]\ttrain-mlogloss:0.20217\tval-mlogloss:0.83168\n",
      "[53]\ttrain-mlogloss:0.19460\tval-mlogloss:0.82362\n",
      "[54]\ttrain-mlogloss:0.18736\tval-mlogloss:0.81585\n",
      "[55]\ttrain-mlogloss:0.18047\tval-mlogloss:0.80833\n",
      "[56]\ttrain-mlogloss:0.17381\tval-mlogloss:0.80117\n",
      "[57]\ttrain-mlogloss:0.16749\tval-mlogloss:0.79407\n",
      "[58]\ttrain-mlogloss:0.16136\tval-mlogloss:0.78726\n",
      "[59]\ttrain-mlogloss:0.15554\tval-mlogloss:0.78071\n",
      "[60]\ttrain-mlogloss:0.14995\tval-mlogloss:0.77428\n",
      "[61]\ttrain-mlogloss:0.14461\tval-mlogloss:0.76805\n",
      "[62]\ttrain-mlogloss:0.13946\tval-mlogloss:0.76190\n",
      "[63]\ttrain-mlogloss:0.13456\tval-mlogloss:0.75611\n",
      "[64]\ttrain-mlogloss:0.12977\tval-mlogloss:0.75040\n",
      "[65]\ttrain-mlogloss:0.12523\tval-mlogloss:0.74475\n",
      "[66]\ttrain-mlogloss:0.12090\tval-mlogloss:0.73936\n",
      "[67]\ttrain-mlogloss:0.11676\tval-mlogloss:0.73434\n",
      "[68]\ttrain-mlogloss:0.11277\tval-mlogloss:0.72945\n",
      "[69]\ttrain-mlogloss:0.10894\tval-mlogloss:0.72459\n",
      "[70]\ttrain-mlogloss:0.10526\tval-mlogloss:0.71967\n",
      "[71]\ttrain-mlogloss:0.10175\tval-mlogloss:0.71504\n",
      "[72]\ttrain-mlogloss:0.09840\tval-mlogloss:0.71048\n",
      "[73]\ttrain-mlogloss:0.09513\tval-mlogloss:0.70621\n",
      "[74]\ttrain-mlogloss:0.09201\tval-mlogloss:0.70196\n",
      "[75]\ttrain-mlogloss:0.08903\tval-mlogloss:0.69779\n",
      "[76]\ttrain-mlogloss:0.08616\tval-mlogloss:0.69377\n",
      "[77]\ttrain-mlogloss:0.08342\tval-mlogloss:0.68989\n",
      "[78]\ttrain-mlogloss:0.08079\tval-mlogloss:0.68612\n",
      "[79]\ttrain-mlogloss:0.07825\tval-mlogloss:0.68241\n",
      "[80]\ttrain-mlogloss:0.07583\tval-mlogloss:0.67885\n",
      "[81]\ttrain-mlogloss:0.07350\tval-mlogloss:0.67542\n",
      "[82]\ttrain-mlogloss:0.07123\tval-mlogloss:0.67206\n",
      "[83]\ttrain-mlogloss:0.06907\tval-mlogloss:0.66868\n"
     ]
    }
   ],
   "source": [
    "n_threads = 64\n",
    "n_epochs = 500\n",
    "model = None\n",
    "model_trained = ML(X_train, y_train, X_val, y_val, model, n_threads, n_epochs, xyz_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-merchant",
   "metadata": {},
   "source": [
    "# Save XGBoost model\n",
    "\n",
    "Save trained model in the \"Results/\" folder. The model will be named after the loaded PDF dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "useful-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_name = big_seed37\n",
    "model_trained.save_model(\"Models/XGBmodel_\" + folder_name + \".model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
